{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Discriminant Analysis\n",
    "\n",
    "Learned\n",
    "- Use numpy matrix/vector operations to replace iterating\n",
    "- Without broadcasting, easier to understand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDA:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        #convert X, Y df's to numpy arrays\n",
    "        self.X_train = X.to_numpy()\n",
    "        self.Y_train = Y.to_numpy()\n",
    "\n",
    "        #identify classes and #\n",
    "        self.classes = np.unique(self.Y_train)\n",
    "        self.num_classes = len(np.unique(self.Y_train))\n",
    "        self.num_features = self.X_train.shape[1]\n",
    "\n",
    "        #initialize means, vars, and priors into matrix\n",
    "        self.means_matrix = np.zeros((self.num_classes,self.num_features))\n",
    "        self.cov_matrix = np.zeros(self.num_features,self.num_features)\n",
    "        self.class_priors = np.zeros(self.num_classes)\n",
    "\n",
    "        for i, cls in enumerate(self.classes):\n",
    "            #for each class, take input data\n",
    "            X_cls = X[Y == cls]\n",
    "            #calculate mean for input vectors across class\n",
    "            class_mean = np.mean(X_cls, axis=0)\n",
    "            #input into means matrix\n",
    "            self.means_matrix[i, :] = class_mean\n",
    "            #add class into cov matrix\n",
    "            self.cov_matrix += ((X_cls - class_mean).T) @ (X_cls - class_mean)\n",
    "\n",
    "        #normalize\n",
    "        self.cov_matrix /= len(self.X_train)\n",
    "\n",
    "    def predict(self,X):\n",
    "        self.X_pred = X.to_numpy()\n",
    "        log_likelihoods = np.zeros(self.num_classes)\n",
    "\n",
    "        #determinant of cov matrix\n",
    "        det_cov_matrix = np.linalg.det(self.cov_matrix)\n",
    "    \n",
    "        #the inverse of the covariance matrix\n",
    "        inv_cov_matrix = np.linalg.inv(self.cov_matrix)\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            mu_cls = self.means_matrix[i]\n",
    "            prior_cls = self.class_priors[i]\n",
    "            \n",
    "            #compute the difference between the data point and the class mean\n",
    "            diff = X - mu_cls\n",
    "            \n",
    "            #compute the quadratic form\n",
    "            quadratic_form = diff.T @ inv_cov_matrix @ diff\n",
    "            \n",
    "            #compute the log-likelihood\n",
    "            log_likelihood = -0.5 * np.log(det_cov_matrix) - 0.5 * quadratic_form + np.log(prior_cls)\n",
    "            \n",
    "            #store the log-likelihood for this class\n",
    "            log_likelihoods[i] = log_likelihood\n",
    "\n",
    "        #predict the class with the highest log-likelihood, return\n",
    "        predicted_class = np.argmax(log_likelihoods)\n",
    "        return predicted_class\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
