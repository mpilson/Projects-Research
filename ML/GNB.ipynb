{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes\n",
    "\n",
    "Learned:\n",
    "- Broadcasting: essentially, by adding dimension to dataset, np infers calculation and fills in gaps, add dimension where you want the iteration, so for X - u, want delta between each feature vector and means of all the classes, so add dimension to rows, as now each row is 2D matrix of differences\n",
    "- np has some super useful interactions, usually way to get around iterating\n",
    "- NB good intro/first stab at problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNB:\n",
    "    def __init__(self, var_smoothing = 1e-9):\n",
    "        #set var smoothing\n",
    "        if not(isinstance(var_smoothing,float)):\n",
    "            raise TypeError(\"Not valid float\")\n",
    "        else:\n",
    "            self.var_smoothing = var_smoothing\n",
    "\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        #convert X, Y df's to numpy arrays\n",
    "        self.X_train = X.to_numpy()\n",
    "        self.Y_train = Y.to_numpy()\n",
    "\n",
    "        #identify classes and #\n",
    "        self.classes = np.unique(self.Y_train)\n",
    "        self.num_classes = len(np.unique(self.Y_train))\n",
    "\n",
    "        #initialize means, vars, and priors into matrix\n",
    "        self.means = np.zeros((self.num_classes,X.shape[1]))\n",
    "        self.vars = np.zeros((self.num_classes,X.shape[1]))\n",
    "        self.class_priors = np.zeros(self.num_classes)\n",
    "\n",
    "        for i, cls in enumerate(self.classes):\n",
    "            #for each class, take input data\n",
    "            X_cls = X[Y == cls]\n",
    "\n",
    "            #for corresponding index to class, take the mean of each col\n",
    "            self.means[i, :] = np.mean(X_cls, axis=0)\n",
    "            #take variance and add smoohting to ensure numerical stability\n",
    "            self.vars[i, :] = np.var(X_cls, axis=0) + self.var_smoothing\n",
    "            #proportion of data in class / total data\n",
    "            self.class_priors[i] = len(X_cls) / len(X)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        #convert to numpy array\n",
    "        self.X_pred = X.to_numpy()\n",
    "\n",
    "        #calculate log probabilities for numerical stability and computational efficiency\n",
    "        #P(Y)\n",
    "        log_class_priors = np.log(self.class_priors)\n",
    "        #use broadcasting and matrix/vector operations to avoid hassle\n",
    "        log_likelihoods = -0.5 * (np.log(2 * np.pi * self.vars) + ((self.X_pred[:, np.newaxis, :] - self.means) ** 2 / self.vars))\n",
    "\n",
    "        #sum log likelihoods across features, so 2D matrix, each row is datum, each is likelihood for the class\n",
    "        #P(X|Y)\n",
    "        log_likelihoods = np.sum(log_likelihoods, axis=2)\n",
    "        \n",
    "        #calculate posterior probabilities\n",
    "        log_posteriors = log_class_priors + log_likelihoods\n",
    "\n",
    "        #take arg max across rows, so find column index that yields max value, then find class\n",
    "        return self.classes[np.argmax(log_posteriors, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639344262295082\n"
     ]
    }
   ],
   "source": [
    "my_GNB = GNB()\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "X = df[['trtbps','chol']]\n",
    "Y = df[\"output\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "my_GNB.fit(X_train,Y_train)\n",
    "Y_pred = my_GNB.predict(X_test)\n",
    "accuracy = accuracy_score(Y_pred, Y_test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
